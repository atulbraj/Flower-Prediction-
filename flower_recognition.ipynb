{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G76mBbgUezGg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIkiDoBie5X_",
        "outputId": "de3af503-0f01-4953-972c-b0d5169b2b4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxQytE9JezGk",
        "outputId": "1a49e694-211b-4cd7-fefd-de3240040fe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4317 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/Colab Notebooks/flowers',\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkOGVHF5ezGl",
        "outputId": "2ee5c312-79cb-41ce-9a4e-17674d207f72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1003 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/test_set',\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSIXsvZoezGl"
      },
      "outputs": [],
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4yGIrdUezGl"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=64 , kernel_size=3 , activation='relu' , input_shape=[64,64,3]))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQA_mz90ezGm"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=64 , kernel_size=3 , activation='relu' ))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2 , strides=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9qpx2wkezGm"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dropout(0.5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TOkeahOezGm"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouykIOLCezGn"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgAcJoEXezGn"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=5 , activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--uouj5fezGn"
      },
      "outputs": [],
      "source": [
        "cnn.compile(optimizer = 'rmsprop' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Submission Purpose only we have trained it on 2 Epochs."
      ],
      "metadata": {
        "id": "PbvDG9atp5OI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUiFPLDGezGn",
        "outputId": "081d1e25-1467-4682-cb98-3717e80c4793"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "135/135 [==============================] - 78s 567ms/step - loss: 1.3425 - accuracy: 0.4181 - val_loss: 1.0518 - val_accuracy: 0.5862\n",
            "Epoch 2/10\n",
            "135/135 [==============================] - 71s 522ms/step - loss: 1.0795 - accuracy: 0.5691 - val_loss: 1.0262 - val_accuracy: 0.6092\n",
            "Epoch 3/10\n",
            "135/135 [==============================] - 74s 547ms/step - loss: 0.9859 - accuracy: 0.6139 - val_loss: 0.9579 - val_accuracy: 0.6461\n",
            "Epoch 4/10\n",
            "135/135 [==============================] - 71s 528ms/step - loss: 0.9019 - accuracy: 0.6470 - val_loss: 0.8887 - val_accuracy: 0.6670\n",
            "Epoch 5/10\n",
            "135/135 [==============================] - 70s 517ms/step - loss: 0.8428 - accuracy: 0.6738 - val_loss: 0.8485 - val_accuracy: 0.6859\n",
            "Epoch 6/10\n",
            "135/135 [==============================] - 69s 507ms/step - loss: 0.8088 - accuracy: 0.6884 - val_loss: 0.7784 - val_accuracy: 0.6969\n",
            "Epoch 7/10\n",
            "135/135 [==============================] - 72s 535ms/step - loss: 0.7867 - accuracy: 0.7016 - val_loss: 0.7784 - val_accuracy: 0.6999\n",
            "Epoch 8/10\n",
            "135/135 [==============================] - 65s 484ms/step - loss: 0.7456 - accuracy: 0.7123 - val_loss: 0.8066 - val_accuracy: 0.6640\n",
            "Epoch 9/10\n",
            "135/135 [==============================] - 67s 496ms/step - loss: 0.7104 - accuracy: 0.7301 - val_loss: 0.6716 - val_accuracy: 0.7587\n",
            "Epoch 10/10\n",
            "135/135 [==============================] - 74s 550ms/step - loss: 0.6882 - accuracy: 0.7355 - val_loss: 0.6381 - val_accuracy: 0.7697\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79c3aef87e80>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "cnn.fit(x = training_set , validation_data = test_set , epochs = 10 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hUAEHmXezGo",
        "outputId": "335188da-206d-4722-9920-85f64c99278f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 38ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'daisy': 0, 'dandelion': 1, 'rose': 2, 'sunflower': 3, 'tulip': 4}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('/content/test.jfif',target_size=(64,64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image,axis=0)\n",
        "result = cnn.predict(test_image)\n",
        "training_set.class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4PuusHPezGo",
        "outputId": "602fa555-e569-4332-969e-10eff7bf06dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your Flower is Rose\n"
          ]
        }
      ],
      "source": [
        "if result[0][0]==1:\n",
        "    print('Your Flower is Daisy')\n",
        "elif result[0][1]==1:\n",
        "    print('Your Flower is Dandelion')\n",
        "elif result[0][2]==1:\n",
        "    print('Your Flower is Rose')\n",
        "elif result[0][3]==1:\n",
        "    print('Your Flower is SunFlower')\n",
        "elif result[0][4]==1:\n",
        "    print(\"Your Flower is Tulip\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}